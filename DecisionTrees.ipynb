{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a href=\"http://datamics.com/de/courses/\"><img src=../DATA/bg_datamics_top.png></a><em text-align:center>© Datamics</em>"},{"metadata":{},"cell_type":"markdown","source":"# Decision Trees und Random Forests Projekt - Lösungen\n\nFür dieses Projekt werden wir öffentlich verfügbare Daten von [LendingClub.com](https://de.wikipedia.org/wiki/Lending_Club) verwenden. Lending Club bringt Leute zusammen, die Geld brauchen (Leihende) und solche, die Geld investieren möchten (Geldgeber). Als Invester möchte man dann verständlicherweise vor allem an die Leute sein Geld verleihen, die es mit einer hohen Wahrscheinlichkeit zurückzahlen. Wir werden versuchen ein Modell zu erstellen, dass bei dieser Vorhersage hilft.\n\nWir werden Daten von 2007 bis 2010 verwenden, bevor das Unternehmen an die Börse ging. Anhand der Daten werden wir versuchen vorherzusagen, ob ein Leihender das Geld zurückgezahlt hat oder nicht. Die Daten haben wir als CSV in den Kursunterlagen beigefügt. Diese Datei wurde bereits um die nicht verfügbaren Einträge gesäubert.\n\nSchauen wir uns noch die verfügbaren Spalten an:\n\n* credit.policy: 1 falls der Kunde die Risikobewertung besteht, 0 falls nicht.\n* purpose: Der Zweck des Kreidts (Werte sind \"credit_card\", \"debt_consolidation\", \"educational\", \"major_purchase\", \"small_business\", und \"all_other\").\n* int.rate: Der Zinssatz des Kreidts als Anteil (eine Rate von 11% würde 0.11 sein). Kreditnehmer, die LendingClub.com als riskanter einstuft erhalten einen höheren Zins.\n* installment: Die monatliche Zeilzahlung, die der Kreditnehmer leistet, wenn der Kredit finaziert wird.\n* log.annual.inc: Der natürliche Log des angegebenen jährlichen Einkommens des Kreditnehmers.\n* dti: Die \"debt-to-income\" Rate des Kreditnehmers (Kredit geteilt durch jährliches Einkommen.\n* fico: Der FICO Kreditscore des Kreditnehmers.\n* days.with.cr.line: Anzahl der Tage an denen der Kunde einen Dispokredit hatte.\n* revol.bal: Die Bilanz am Ende eines Kreditkartenabrechnungszeitraums.\n* revol.util: Der erstattete Anteil am Gesamtkredit.\n* inq.last.6mths: Die Anzahl an Anfragen, die Kreditgeber in den letzten 6 Monaten an den Kreditnehmer gestellt haben.\n* delinq.2yrs: Die Anzahl der Vorkommnisse eines Verzugs von über 30 Tagen innerhalb der letzten 2 Jahre.\n* pub.rec:  Die Anzahl an negativen Einträgen (Bankrott, Steuerverzug, Verurteilungen,...) des Kreditnehmers."},{"metadata":{},"cell_type":"markdown","source":"## Libraries importieren\n\n**Importiere die üblichen Libraries für Pandas und zur Visualisierung. Sklearn können wir später noch importieren.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\nimport io","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r = requests.get(\"https://github.com/Soley02/DecisionTree/blob/master/Loan_Data.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Die Daten laden\n\n**Nutze Pandas, um die Datei \"Loan_Data.csv\" als DataFrame namens \"loans\" zu laden.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"loans = pd.read_csv('Loan_Data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Schau dir die info(), head() und describe() Methoden für loans an.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"loans.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loans.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loans.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explorative Daten Analyse\n\nVisualisieren wir nun einige Daten! Wie nutzen dazu Seaborn und Pandas eingebaute VIsualisierungsfähigkeiten. Wer möchte kann aber auch andere Methoden verwenden. Die Farben müssen z.B. nicht genau übereinstimmen. Es geht hier darum ein Verständnis für die Daten zu entwickeln!\n\n**Erstelle ein Histogram zweier FICO Verteilungen übereinandern, je eins nach dem credit.policy Ergebnis.**\n\n*Hinweis: Das ist bereits etwas knifflig. Keine Sorge, die Lösung hilft im Zweifelsfall weiter! Meine Empfehlung ist die Verwendung von Pandas .hist() Funktion.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nloans[loans['credit.policy']==1]['fico'].hist(alpha=0.5,color='blue',\n                                              bins=30,label='Credit.Policy=1')\nloans[loans['credit.policy']==0]['fico'].hist(alpha=0.5,color='red',\n                                              bins=30,label='Credit.Policy=0')\nplt.legend()\nplt.xlabel('FICO')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Erstelle ein gleiches Diagramm, dass diesesmal nach der \"not.fully.paid\" Spalte trennt.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nloans[loans['not.fully.paid']==1]['fico'].hist(alpha=0.5,color='blue',\n                                              bins=30,label='not.fully.paid=1')\nloans[loans['not.fully.paid']==0]['fico'].hist(alpha=0.5,color='red',\n                                              bins=30,label='not.fully.paid=0')\nplt.legend()\nplt.xlabel('FICO')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Erstelle ein Countplot unter Verwendung von Seaborn, das die Anzahl der Leihgaben (en. loans) nach Zweck (en. purpose) anzeigt. Der Hue soll dabei durch die Spalte \"not.fully.paid\" definiert sein.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(11,7))\nsns.countplot(x='purpose',hue='not.fully.paid',data=loans,palette='Set1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lasst uns den Trend zwischen FICO Score und den Zinsen (en. interest rate) betrachten. Stelle dazu das folgende Jointplot nach.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x='fico',y='int.rate',data=loans,color='purple')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Erstelle die folgenden lmplots, um zu sehen, ob sich der Trend zwischen \"not.fully.paid\" und \"credit.policy\" unterscheidet. Schau in die Dokumentation von lmplot, wenn du nicht mehr weißt, wie man in zwei Spalten aufteilt.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(11,7))\nsns.lmplot(y='int.rate',x='fico',data=loans,hue='credit.policy',\n           col='not.fully.paid',palette='Set1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Die Daten vorbereiten\n\nBereiten wir unsere Daten nun für ein Random Forest Klassifikationsmodell vor!\n\n**Schaue dir erneut loans.info() an.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"loans.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Kategorische Eigenschaften\n\nAchte darauf, dass die Spalte \"purpose\" (dt. Zweck) kategorisch ist. Das bedeutet wir müssen sie in Dummy-Variablen umwandeln, damit sklearn mit ihnen arbeiten kann. Für diesen Schritt verwenden wir `pd.get_dummies`.\n\nDieses Vorgehen kann auf weitere kategorische Inhalte angewendet werden, wenn es nötig sein sollte.\n\n**Erstelle eine Liste, die nur ein Element enthält. Dieses Element soll der String \"purpose\" sein. Nenne diese Liste cat_feats.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_feats = ['purpose']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Nutze jetzt pd.get_dummies(loans,columns=cat_feats,drop_first=True), um einen korrigierten und größeren DataFrame zu erstellen. Nenne diesen DataFrame final_data.**\n\n*Hinweis: Um mehrere kategorische Eigenschaften in Dummy-Variablen zu übertragen füge die entsprechenden Spalten einfach der Liste aus dem vorherigen Arbeitsschritt hinzu. Für unseren Datensatz hier müssen wir allerdings keine weitere Spalte berücksichtigen.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_data = pd.get_dummies(loans,columns=cat_feats,drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Test Split\n\nJetzt ist es an der Zeit unsere Daten aufzuteilen. \n\n**Nutze sklearn um unsere Daten in Trainings- und Testset aufzuteilen. Diesen Vorgang kennst du schon aus vorherigen Abschnitten.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = final_data.drop('not.fully.paid',axis=1)\ny = final_data['not.fully.paid']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ein Entscheidungsbaummodell trainieren\n\nBeginnen wir damit einen einfachen Entscheidungsbaum zu trainieren!\n\n**Importiere den DecisionTreeClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Erstelle eine Instanz des DecisionTreeClassifier() namens dtree und fitte die Trainingsdaten darauf.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree = DecisionTreeClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vorhersage und Auswertung\n\n**Erstelle die Vorhersagen (en. predictions) aus den Testdaten und werte dann Classification Report und Confusion Matrix aus.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = dtree.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ein Random Forest Modell trainieren\n\nJetzt trainieren wir ein ganzes Modell!\n\n**Erstelle eine Instanz des RandomForestClassifier und fitte die Trainignsdaten aus unserem vorherigen Schritt darauf.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=600)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vorhersage und Auswertung\n\nJetzt können wir für y_test Werte vorhersagen und das Ergebnis auswerten.\n\n**Sage die Klasse von not.fully.paid für die X_test Daten vorher.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Erstelle jetzt einen Classification Report aus den Ergebnissen. Erhälst du etwas komisches oder eine Art Warnung?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Zeige jetzt noch die Confusion Matrix der Vorhersagen an.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Welche Methode hat besser performt?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Kommt darauf an welche Metrik wir optimieren\n# Achte auf den Recall beider Modelle\n# Keiner war besonders gut \n# -> Wir müssen die Eigenschaften besser anpassen","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gut gemacht!"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.8.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}